################################################################################
# SLURM CONFIGURATION FILE
# System: 24-core, 255GB RAM, 2x RTX 5090
# Last updated: 2025-11-11
################################################################################

################################################################################
# CLUSTER IDENTITY
################################################################################
# ClusterName: Give your cluster a memorable name
ClusterName=munin
SlurmUser=slurm

# SlurmctldHost: The machine running the controller daemon
# For single-machine setup, this is localhost
SlurmctldHost=localhost

################################################################################
# AUTHENTICATION & SECURITY
################################################################################
# AuthType: Use MUNGE for authentication (requires munge daemon running)
AuthType=auth/munge

# CryptoType: Use MUNGE for message encryption
CryptoType=crypto/munge

################################################################################
# LOGGING CONFIGURATION
################################################################################
# Log file locations - useful for troubleshooting
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdLogFile=/var/log/slurm/slurmd.log

# PID file locations
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmdPidFile=/var/run/slurmd.pid

# Debug levels: quiet, fatal, error, info, verbose, debug, debug2-5
# Use 'info' for normal operation, 'debug' for troubleshooting
SlurmctldDebug=info
SlurmdDebug=info

################################################################################
# STATE PRESERVATION
################################################################################
# Where to save controller state (for restarts)
StateSaveLocation=/var/spool/slurm/ctld

# Where compute nodes store temporary job data
SlurmdSpoolDir=/var/spool/slurm/d

################################################################################
# SCHEDULING CONFIGURATION
################################################################################
# SchedulerType: backfill allows jobs to start early if they don't delay others
SchedulerType=sched/backfill

# SelectType: cons_tres enables fine-grained resource tracking (CPUs, memory, GPUs)
SelectType=select/cons_tres

# SelectTypeParameters: Track cores and memory separately
# CR_Core_Memory = allocate cores and memory independently
SelectTypeParameters=CR_Core_Memory

################################################################################
# RESOURCE TRACKING
################################################################################
# AccountingStorageType: Set to 'accounting_storage/slurmdbd' if you want
# detailed job accounting and history. 'none' is simpler for single-machine setup
AccountingStorageType=accounting_storage/none

# Job accounting - tracks CPU, memory, I/O usage
JobAcctGatherType=jobacct_gather/linux
JobAcctGatherFrequency=30

# GresTypes: Generic resources to track (GPUs in this case)
GresTypes=gpu

################################################################################
# PROCESS TRACKING & CONTROL
################################################################################
# ProctrackType: Use cgroups for reliable process tracking and cleanup
ProctrackType=proctrack/cgroup

# TaskPlugin: Use cgroups to constrain job resources
TaskPlugin=task/cgroup

################################################################################
# TIMEOUT CONFIGURATION
################################################################################
# How long to wait before considering controller/daemon dead (seconds)
SlurmctldTimeout=300
SlurmdTimeout=300

# InactiveLimit: How long a job can run without activity (0 = unlimited)
InactiveLimit=0

# MinJobAge: How long to keep completed job info in memory (seconds)
MinJobAge=300

# KillWait: Time to wait between SIGTERM and SIGKILL when canceling jobs
KillWait=30

# Waittime: How long to wait for a node to respond (0 = use default)
Waittime=0

################################################################################
# NODE RECOVERY
################################################################################
# ReturnToService: How nodes return to service after being down
# 0 = manual intervention required
# 1 = return when registered with valid config
# 2 = return even if config changed (use for single-node setup)
ReturnToService=2

################################################################################
# DEFAULT JOB LIMITS
################################################################################
# These can be overridden by users in their job scripts using --time, --mem, etc.

# DefMemPerCPU: Default memory per CPU if not specified (MB)
# Users can override with: #SBATCH --mem-per-cpu=8000
DefMemPerCPU=4000

# MaxMemPerCPU: Maximum memory per CPU unless user has special permission (MB)
MaxMemPerCPU=16000

################################################################################
# GLOBAL JOB SUBMISSION LIMITS
################################################################################
# MaxSubmitJobsPerAccount: Maximum number of jobs each account can have
# in the system at once (pending + running). Set to 0 for unlimited.
# Note: This requires AccountingStorageType to be set to something other than 'none'
# For simple setups without accounting, this parameter won't work.
# MaxSubmitJobsPerAccount=10

# Note: To use job limits per user/account, you need to set up slurmdbd
# For now, control is done via MaxCPUsPerNode in partitions


################################################################################
# NODE CONFIGURATION
################################################################################
# Define your physical hardware
# CPUs: Set to 20 (reserving 4 cores for desktop use)
# RealMemory: Set to 220000 MB (~215GB, reserving ~40GB for desktop)
# Gres: 2x RTX 5090 GPUs available for scheduling
# State: UNKNOWN is normal for initial config

NodeName=localhost CPUs=20 RealMemory=220000 Gres=gpu:rtx5090:2 State=UNKNOWN

################################################################################
# PARTITION CONFIGURATION
################################################################################
# Partitions are like job queues with different policies
# Users select partition with: #SBATCH --partition=gpu

# Main GPU partition
PartitionName=standard \
    Nodes=localhost \
    Default=YES \
    MaxTime=48:00:00 \
    State=UP \
    DefaultTime=01:00:00 \
    MaxCPUsPerNode=8 \
    Priority=50

# Partition parameters explained:
# - Default=YES: Jobs go here unless user specifies otherwise
# - MaxTime=INFINITE: No hard limit on job runtime (users can override)
# - DefaultTime=01:00:00: Jobs default to 1 hour if --time not specified
#   Users can override with: #SBATCH --time=08:00:00
# - MaxCPUsPerNode=16: Prevents single job from using all CPUs
#   (keeps 4 reserved for desktop + 4 for other jobs)

################################################################################
# OPTIONAL: Additional partitions for different use cases
################################################################################
# Uncomment these if you want separate queues for different priorities

# High-priority partition (for your scheduled LLM or urgent jobs)
PartitionName=priorityLLM \
    Nodes=localhost \
    Default=NO \
    MaxTime=INFINITE \
    State=UP \
    DefaultTime=08:00:00 \
    MaxCPUsPerNode=8 \
    Priority=100

# High-priority partition - 70B LLM (dual GPU, 16 CPUs)
PartitionName=priorityLLMv2 \
    Nodes=localhost \
    Default=NO \
    MaxTime=INFINITE \
    State=UP \
    DefaultTime=08:00:00 \
    MaxCPUsPerNode=16 \
    Priority=150

# Short jobs partition (for quick tests)
PartitionName=quickdirty \
    Nodes=localhost \
    Default=NO \
    MaxTime=01:00:00 \
    State=UP \
    DefaultTime=00:15:00 \
    MaxCPUsPerNode=8 \
    Priority=150

################################################################################
# EDITING TIPS
################################################################################
# After editing this file:
# 1. Check syntax: slurmctld -t
# 2. Restart services: sudo systemctl restart slurmctld slurmd
# 3. Verify changes: scontrol show config | grep -i <parameter>
# 4. Verify changes (opt): scontrol show config
#
# Common parameters to adjust:
# - CPUs/RealMemory in NodeName: Match your hardware
# - DefaultTime: Change default job duration
# - MaxCPUsPerNode: Adjust CPU limits per job
# - DefMemPerCPU/MaxMemPerCPU: Adjust memory limits
################################################################################
